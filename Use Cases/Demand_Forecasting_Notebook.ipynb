{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SfpcGwm-q51"
   },
   "source": [
    "## How-to guide for Demand Forecasting use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a forecasting model using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [Store Sales Data](https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_sales_w_holidays_timeseries.csv) and [Store Attributes](https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_metadata.csv) datasets, which contain information about multiple stores' sales and their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86-amG5MVlv9"
   },
   "source": [
    "1. Install the Abacus.AI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDFMTaef6FV2",
    "outputId": "74d70337-f3ea-4fd3-ba1e-ef8145a040cb"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9Xj_eYXVntL"
   },
   "source": [
    "We'll also import pandas and pprint tools for neat visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcwfHka1QqcK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # A tool we'll use to download and preview CSV files\n",
    "import pprint # A tool to pretty print dictionary outputs\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIZO6YCZVqln"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDghrVmKQrg7"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "\n",
    "api_key = ''  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4uBc3OtVs6C"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9uIxZfAQtzh"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzePW7fyVvMl"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model catered specifically for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts0RBfwnQvMr",
    "outputId": "6e6b6dea-ddef-4483-8212-bc60774b1ec5"
   },
   "outputs": [],
   "source": [
    "client.list_use_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4mjNiWzVxUB"
   },
   "source": [
    "In this notebook, we're going to create a forecasting model using the Store Sales Data and Store Attributes datasets. The 'RETAIL' use case is best tailored for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgCCVD-cQwVd"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'RETAIL'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkW3tkWpV-6p"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LD1m3UXWQ3Zb",
    "outputId": "d1d7585f-73ad-4867-951f-007d62f387eb"
   },
   "outputs": [],
   "source": [
    "for requirement in client.describe_use_case_requirements(use_case):\n",
    "  pp.pprint(requirement.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEMPQL7JWAFm"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwakgRFxQ4ug",
    "outputId": "ad01a134-304a-45c0-9b90-bc37a8c7ff77"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_project = client.create_project(name='Store Sales Forecasting', use_case=use_case)\n",
    "demand_forecasting_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2rmNK-QyYIW"
   },
   "source": [
    "**Note: When feature_groups_enabled is True then the use case supports feature groups (collection of ML features). Feature groups are created at the organization level and can be tied to a project to further use it for training ML models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3imQdznBWCwQ"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using two datasets for this notebook. We'll tell Abacus.AI how each dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [Store Sales Data](https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_sales_w_holidays_timeseries.csv) (**TIMESERIES**): \n",
    "This dataset contains information about store sales.\n",
    "- [Sales Attributes](https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_metadata.csv) (**ITEM_ATTRIBUTES**): This dataset contains store attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqIUOPRHvHT"
   },
   "source": [
    "### Add the dataset to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the file, then add it to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "vO0Y7luNHvWr",
    "outputId": "1459dc5d-1fa8-44c7-8a09-7632b7c01ab0"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_sales_w_holidays_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "mSNGZMvAHwQT",
    "outputId": "03805298-a247-4023-874a-da7d3098eb82"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com/realityengines.exampledatasets/sales_forecasting/store_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeR19HoPYTjM"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LubPDtsUdZwU",
    "outputId": "d7b39d24-7b29-41c6-f03c-3cffc0a902d2"
   },
   "outputs": [],
   "source": [
    "store_sales_dataset = client.create_dataset_from_file_connector(name='Store Sales Data',\n",
    "                                     table_name='Store_Sales_Data',\n",
    "                                     location='s3://realityengines.exampledatasets/sales_forecasting/store_sales_w_holidays_timeseries.csv',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "\n",
    "store_attributes_dataset = client.create_dataset_from_file_connector(name='Store Attributes', table_name='Store_Attributes' ,\n",
    "                                     location='s3://realityengines.exampledatasets/sales_forecasting/store_metadata.csv',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "\n",
    "datasets = [store_sales_dataset, store_attributes_dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.wait_for_inspection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jttn4HgryeS9"
   },
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5yK6LbUqFjD"
   },
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='Demand_forecasting',sql='SELECT * FROM Store_Sales_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PKq_l_Wy3NM"
   },
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIkBZNVVqqO3"
   },
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = demand_forecasting_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84exsAHry6mw"
   },
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zk6vVjDuy6t_"
   },
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = demand_forecasting_project.project_id, feature_group_type= \"TIMESERIES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmTxMwybzBWc"
   },
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-fP-naGzIQE",
    "outputId": "99219778-ef02-4d2f-bb6f-94f00c45f825"
   },
   "outputs": [],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XloXedrbYZPI"
   },
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVYDdUeDRMMF",
    "outputId": "9fcc57be-8576-4ed1-cadb-824a91ec9b8f"
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR-qkpGzsCkr",
    "outputId": "e8253d61-449c-4a1a-ad79-09a5f8b21a0f"
   },
   "outputs": [],
   "source": [
    "client.set_feature_mapping(project_id = demand_forecasting_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='Store',feature_mapping='ITEM_ID')\n",
    "client.set_feature_mapping(project_id = demand_forecasting_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='Sales',feature_mapping='DEMAND')\n",
    "client.set_feature_mapping(project_id = demand_forecasting_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='Date',feature_mapping='DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1g4NLkDaix-"
   },
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48n5jAjoRPas",
    "outputId": "81ad6b54-be56-4aa1-b914-a701901ba17b"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_project.validate(feature_group_ids=[feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMilDDIFagvw"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3-9JT_PanOx"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1AoE9GbRQ1H",
    "outputId": "2c17ca53-cd54-4e2a-8813-06d0a48f30c8"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_project.get_training_config_options(feature_group_ids=[feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhtpojWUap6d"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWK7tl22RR8I",
    "outputId": "d179575d-31ee-4852-e1b0-766cea3f21e1"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_model = demand_forecasting_project.train_model(training_config={},feature_group_ids=[feature_group.feature_group_id])\n",
    "demand_forecasting_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzOdliWPasQI"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqkTK1HERTCw"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_model.wait_for_full_automl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DcrB0crz1sZ"
   },
   "source": [
    "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS1n0ux4a-4q"
   },
   "source": [
    "## **Checkpoint** [Optional]\n",
    "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMCt0wyDa_Z5"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)\n",
    "demand_forecasting_project = next(project for project in client.list_projects() if project.name == 'Store Sales Forecasting')\n",
    "demand_forecasting_model = demand_forecasting_project.list_models()[-1]\n",
    "demand_forecasting_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ5CdVUWbRXw"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWYmFmroRUWM"
   },
   "outputs": [],
   "source": [
    "pp.pprint(demand_forecasting_model.get_metrics().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pOSL213bVJr"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/RETAIL/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cH-q-HmMbb-C"
   },
   "source": [
    "## 5. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deLW72q9bfBJ"
   },
   "source": [
    "After the model has been trained, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzmWmzk1RXeK"
   },
   "outputs": [],
   "source": [
    "deployment_token = demand_forecasting_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8cKW56WbdWL"
   },
   "source": [
    "Now we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNDAUuHARVsz"
   },
   "outputs": [],
   "source": [
    "demand_forecasting_deployment = client.create_deployment(name='Store Sales Deployment',description='Store Sales Deployment',model_id=demand_forecasting_model.model_id)\n",
    "demand_forecasting_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMNq7WPObjyi"
   },
   "source": [
    "## 6. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT7y7v6TblTF"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_forecast` API call below.\n",
    "\n",
    "This command will return a forecast under each percentile for the specified store. With the dataset we've specified, the forecast is made based on a pattern in the number of sales for the specified store/entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kyn_yIIxUugS"
   },
   "outputs": [],
   "source": [
    "ApiClient().get_forecast(deployment_token=deployment_token, \n",
    "               deployment_id=demand_forecasting_deployment.deployment_id, \n",
    "               query_data={\"Store\":\"1\"})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demand Forecasting Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a444a4e97a0365a8a152d6b3286685b7a3c540a2b13f4d560bd58f028f75a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
