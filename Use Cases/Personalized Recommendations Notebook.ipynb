{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqLrTPv8b7le"
   },
   "source": [
    "# How-to guide for Personalized Recommendations use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a model that creates personalized recommendations using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv), [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv), and [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) datasets, each of which has information about the user and/or their choice of movies.\n",
    "\n",
    "\n",
    "## Table of content\n",
    "[Installation and imports](#scrollTo=-CHABbdhcDZg)\n",
    "\n",
    "[1. Create a Project](#scrollTo=j_6LiH43cM9Z)\n",
    "\n",
    "[2. Add Datasets to your Project](#scrollTo=8O41vBUQcgxN)\n",
    "\n",
    "[3. Train a Model](#scrollTo=RWvYvPEmdfg7)\n",
    "\n",
    "[(Checkpoint)](#scrollTo=C0mIg2VHdnfA)\n",
    "\n",
    "[4. Evaluate your Model Metrics](#scrollTo=jBK2e1WNd6L3)\n",
    "\n",
    "[5. Deploy Model](#scrollTo=Xc5YAK8veBt1)\n",
    "\n",
    "[6. Make Prediction](#scrollTo=BzFpIsJ_eGmk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CHABbdhcDZg"
   },
   "source": [
    "## Installation and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-2wF3btAglZ"
   },
   "source": [
    "1. Install the Abacus.AI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1609877999687,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "-wgbLfJjtBoE",
    "outputId": "28382897-dad5-404c-8f36-8047112c1f89"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EYIz02FcFEo"
   },
   "source": [
    "We'll also import pandas for visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7857,
     "status": "ok",
     "timestamp": 1609878002257,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "VGTCGEUntL9Z",
    "outputId": "e1240fbe-c206-43c9-f7ae-eb6ae9f63fa2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # A tool we'll use to download and preview CSV files\n",
    "pd.set_option('display.max_colwidth', None)  # We set the max_colwidth to None to have an unlimited width of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEZVhZaYcGon"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1609878135718,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "Py71-cbbtNKX"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "api_key = ''  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBcZRI2_cIe2"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1609878139367,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "z5xwrkD6tOVT"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_6LiH43cM9Z"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model possible for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the available Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1609878140975,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ZnIKg-SutPZU",
    "outputId": "87f1e871-0ad5-4f22-8fd2-9b30d0e4a22b"
   },
   "outputs": [],
   "source": [
    "use_cases = client.list_use_cases()\n",
    "use_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X824DYzaBrg7"
   },
   "source": [
    "We can use pandas to pretty-print the use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1609878144039,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "WYqJor8HB46J",
    "outputId": "6b654d86-6c28-4386-e7d3-b6ed4c6c56b5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(use_case.to_dict() for use_case in use_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHRg5caCcWq1"
   },
   "source": [
    "In this notebook, we're going to create a model that creates personalized recommendations using the User Item Recommendations, Movie Attributes, and User Attributes datasets. The **USER_RECOMMENDATIONS** use case is best tailored for this situation. For the purpose of taking an example, we will use the IMDB movie dataset that has movie metadata, user metadata, and user-movie ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1609878147694,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "in9724URtQlL"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'USER_RECOMMENDATIONS'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cARPh3t8ccl5"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1609878149396,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "5oZW86H6tUVR",
    "outputId": "73fc7782-a5f4-4320-aa3b-9bbc6e0bc0ea"
   },
   "outputs": [],
   "source": [
    "requirements = client.describe_use_case_requirements(use_case)\n",
    "pd.DataFrame(requirement.to_dict() for requirement in requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kR_Zq0Aqceq0"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1547,
     "status": "ok",
     "timestamp": 1609881745309,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ekTMnXyotWKg",
    "outputId": "43cc7efa-cbee-402d-82c9-2fb73101e8aa"
   },
   "outputs": [],
   "source": [
    "recommendations_project = client.create_project(name='Movie Recommendations', use_case=use_case)\n",
    "recommendations_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O41vBUQcgxN"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using three datasets for this notebook. We'll tell Abacus.AI how the datasets should be used when creating them by tagging each dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv) (**USER_ITEM_INTERACTIONS**): \n",
    "This dataset contains information about multiple users' ratings of movies with specified IDs.\n",
    "- [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv) (**CATALOG_ATTRIBUTES**): This dataset contains attributes about movies with specified IDs, such as each movie's name and genre.\n",
    "- [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) (**USER_ATTRIBUTES**): This dataset contains information about users with specified IDs, such as their age, gender, occupation, and zip code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpofeV6ldWam"
   },
   "source": [
    "### Add the datasets to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the files, then add them to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1609878157855,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "OK4QsHHdtmWg",
    "outputId": "554173ee-c229-481b-b7b5-dc1e1f5cc995"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/user_movie_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1609878159734,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "BIPrCtrqtoWy",
    "outputId": "b6d261b1-9cb0-4789-ca7b-59d61cc9bf82"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1609878162053,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "qHf00pKHtohx",
    "outputId": "e3ee8477-d9f8-45ce-8202-ccaa7f6d8458"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/users_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7g0ZLTTcmJj"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "The Refresh Schedule is given with a cron string. For example, when entering \"0 12 * * *\", the dataset is going to be re-read from the s3 at 12pm UTC, so that no update are missed.\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2515,
     "status": "ok",
     "timestamp": 1609881753892,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "yjKasrIStwpm"
   },
   "outputs": [],
   "source": [
    "user_item_dataset = client.create_dataset_from_file_connector(\n",
    "    name='User Item Recommendations',\n",
    "    table_name='User_Item_Recommendations',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/user_movie_ratings.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "movie_attributes_dataset = client.create_dataset_from_file_connector(\n",
    "    name='Movie Attributes',\n",
    "    table_name='Movie_Attributes',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/movies_metadata.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "user_attributes_dataset = client.create_dataset_from_file_connector(\n",
    "    name='User Attributes',\n",
    "    table_name='User_Attributes',\n",
    "    location='s3://abacusai.exampledatasets/user_recommendations/users_metadata.csv',\n",
    "    refresh_schedule='0 12 * * *'\n",
    ")\n",
    "\n",
    "datasets = [user_item_dataset, movie_attributes_dataset, user_attributes_dataset]\n",
    "for dataset in datasets:\n",
    "    dataset.wait_for_inspection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='personalized_recommendations',sql='SELECT * from User_Item_Recommendations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DANKeBcwdZPy"
   },
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = recommendations_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRjRmMMRdcXs"
   },
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = recommendations_project.project_id, feature_group_type= \"USER_ITEM_INTERACTIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113983,
     "status": "ok",
     "timestamp": 1609881875744,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "fr3TVpOUuXZz",
    "outputId": "92660c44-cf8d-4389-c727-5735972e5aa9"
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='movie_id',feature_mapping='ITEM_ID')\n",
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='user_id',feature_mapping='USER_ID')\n",
    "client.set_feature_mapping(project_id = recommendations_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='timestamp',feature_mapping='TIMESTAMP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_project.validate(feature_group_ids=[feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWvYvPEmdfg7"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3grtGDidiNT"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the `get_training_config_options` API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108423,
     "status": "ok",
     "timestamp": 1609881878683,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "sZZ0LDQ9vBsb",
    "outputId": "deb98392-bd6b-4a64-e91a-af37edaad729"
   },
   "outputs": [],
   "source": [
    "training_config_options = recommendations_project.get_training_config_options(feature_group_ids=[feature_group.feature_group_id])\n",
    "training_config_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqpRkZ9sTqzS"
   },
   "source": [
    "To have a nice display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 106309,
     "status": "ok",
     "timestamp": 1609881878686,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "d5inDZc4TwPD",
    "outputId": "a8a8d465-f395-49d9-e4ba-3393170ceea5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(training_config_option.to_dict() for training_config_option in training_config_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjU_ouvAdj67"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning (See the description of the parameters [here](https://abacus.ai/app/help/useCases/user_recommendations/training))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 94722,
     "status": "ok",
     "timestamp": 1609881878687,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "A7ww-YurUhN6"
   },
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    'BATCH_SIZE': None,\n",
    "    'DOWNSAMPLE_ITEM_POPULARITY_PERCENTILE': None,\n",
    "    'DROPOUT_RATE': None,\n",
    "    'EXCLUDE_TIME_FEATURES': None,\n",
    "    'IGNORE_ACTION_WEIGHT_COLUMN': None,\n",
    "    'MAX_HISTORY_LEN': None,\n",
    "    'MAX_USER_HISTORY_LEN_PERCENTILE': None,\n",
    "    'RECENT_DAYS_FOR_TRAINING': None,\n",
    "    'RERANKING_PERSONALIZATION_FACTOR': None,\n",
    "    'SEARCH_QUERY_COLUMN': None,\n",
    "    'SKIP_HISTORY_FILTERING': False,\n",
    "    'TARGET_EVENT_WEIGHTS': None,\n",
    "    'TEST_ON_USER_SPLIT': False,\n",
    "    'TEST_SPLIT': None,\n",
    "    'TRAINING_START_DATE': None,\n",
    "    'UNORDERED_HISTORY': False\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1609881880219,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "MhbOMNj_vxEr",
    "outputId": "9748cb96-6401-4f55-fa20-78da255ab564"
   },
   "outputs": [],
   "source": [
    "recommendations_model = recommendations_project.train_model(training_config=training_config,feature_group_ids=[feature_group.feature_group_id])\n",
    "recommendations_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "529oNyl-dl3Z"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ2BtkogwIM2"
   },
   "outputs": [],
   "source": [
    "recommendations_model.wait_for_full_automl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0mIg2VHdnfA"
   },
   "source": [
    "## **(Checkpoint)**\n",
    "Training can take an hour or two to complete, but we encourage you to run the remaining calls on your own time. If your page times out or you hit refresh, you can restore your progress in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152845,
     "status": "aborted",
     "timestamp": 1609881728395,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "hX9kkcnodpxG"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key) \n",
    "recommendations_project = next(project for project in client.list_projects() if project.name == 'Movie Recommendations')\n",
    "recommendations_model = recommendations_project.list_models()[-1]\n",
    "recommendations_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBK2e1WNd6L3"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125877,
     "status": "aborted",
     "timestamp": 1609881728399,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "0612612IwJ8H"
   },
   "outputs": [],
   "source": [
    "recommendations_model.get_metrics().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP1MNip0d7xM"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/USER_RECOMMENDATIONS/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc5YAK8veBt1"
   },
   "source": [
    "## 5. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4TUE2eveFDl"
   },
   "source": [
    "After the model has been trained, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 121920,
     "status": "aborted",
     "timestamp": 1609881728403,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "AZHiO7jywTed"
   },
   "outputs": [],
   "source": [
    "deployment_token = recommendations_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNqQGB0eDky"
   },
   "source": [
    "Now we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 123824,
     "status": "aborted",
     "timestamp": 1609881728402,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "lS1XcyafwLl_"
   },
   "outputs": [],
   "source": [
    "recommendations_deployment = client.create_deployment(name='Personalized Recommendations Deployment',model_id=recommendations_model.model_id)\n",
    "recommendations_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzFpIsJ_eGmk"
   },
   "source": [
    "## 6. Make Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-la9sapteIEy"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_recommendations` API call below.\n",
    "\n",
    "To see a full description of the prediction API parameters, visit our [documentation](https://abacus.ai/app/help/useCases/USER_RECOMMENDATIONS/predictions) page. \n",
    "\n",
    "NB: The REST API keywords described in the documentation use the CamelCase word convention while the Python API one below use the snake case convention, see [here](https://medium.com/better-programming/string-case-styles-camel-pascal-snake-and-kebab-case-981407998841) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ3wmT97WHBY"
   },
   "source": [
    "For the purpose of data visualization, we store the source file content in Pandas' dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 118623,
     "status": "aborted",
     "timestamp": 1609881728405,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "5p7RMwacWHr2"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/movies_metadata.csv', dtype=object)\n",
    "users = pd.read_csv('https://s3.amazonaws.com//abacusai.exampledatasets/user_recommendations/users_metadata.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot-7qArxWfO6"
   },
   "source": [
    "### Select a User ID\n",
    "\n",
    "The first step is to select a user by inputting his/her user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 115924,
     "status": "aborted",
     "timestamp": 1609881728406,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "CMtXh8t1VV8M"
   },
   "outputs": [],
   "source": [
    "user_id = \"10\" #@param {type: \"string\"}\n",
    "users[users[\"user_id\"] == user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkUMlGr_334G"
   },
   "source": [
    "### Build the query\n",
    "\n",
    "The query is a dictionary with the key being the column used as **ITEM_ID** (in our example, the *movie_id* column) and the value being the corresponding ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 113723,
     "status": "aborted",
     "timestamp": 1609881728408,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ryXudHNi36R2"
   },
   "outputs": [],
   "source": [
    "my_query_data = {\"user_id\": user_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R54Ti8zhdzcz"
   },
   "source": [
    "### Run the Get Recommendations API\n",
    "\n",
    "This command will return a list of recommendations for the user with the specified ID. The recommendation would be determined based on what movies the user liked in the past and how the movies and users are related to each other depending on their attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 112001,
     "status": "aborted",
     "timestamp": 1609881728410,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "IpBUO9EywV53"
   },
   "outputs": [],
   "source": [
    "recommendations = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0NhqJull-Ft"
   },
   "source": [
    "A convenient way to visualize the data is within a Pandas Dataframe, by joining it with the movies dataframe to have the movies' names and genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 108754,
     "status": "aborted",
     "timestamp": 1609881728411,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "SzPjHdiHl-eS"
   },
   "outputs": [],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations).merge(movies, on=\"movie_id\")\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkqvGBWPH_7-"
   },
   "source": [
    "### Set the number of results per page\n",
    "\n",
    "For convenience, the number of recommendations is set to 50 per page by default. You can change the default value by editing the value of the `num_items` keyword. The example below sets the number of pages to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 106117,
     "status": "aborted",
     "timestamp": 1609881728413,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "ta77ndvjVQYN"
   },
   "outputs": [],
   "source": [
    "recommendations_base = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_base_df = pd.DataFrame(recommendations_base).merge(movies, on=\"movie_id\")\n",
    "recommendations_base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDBxTnhtNc_P"
   },
   "source": [
    "You can easily select the page to display with the keyword `page`. For example, let's say that the num_items is set to 10 with the total recommendations list size of 50 recommended items, then an input value of 2 in the `page` keyword will display a list of items that rank from 11th to 20th. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103855,
     "status": "aborted",
     "timestamp": 1609881728414,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "DIh9_5bKNdh8"
   },
   "outputs": [],
   "source": [
    "recommendations_page = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data={\"user_id\":user_id},\n",
    "    num_items=10,\n",
    "    page=2,\n",
    ")\n",
    "recommendations_page_df = pd.DataFrame(recommendations_page).merge(movies, on=\"movie_id\")\n",
    "recommendations_page_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdOn7Gn0dmiC"
   },
   "source": [
    "You can add a column with the relative item scores by specifying the column name for the keyword `score_field` (example: \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 100093,
     "status": "aborted",
     "timestamp": 1609881728416,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "fq4czBfddKmE"
   },
   "outputs": [],
   "source": [
    "recommendations_score = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    "    score_field = \"score\"\n",
    ")\n",
    "recommendations_score_df = pd.DataFrame(recommendations_score).merge(movies, on=\"movie_id\")\n",
    "recommendations_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26oU3n84dnRU"
   },
   "source": [
    "### Use of Scaling Factors to bias the model toward certain items\n",
    "\n",
    "You can use a scaling factor to add a bias toward certain items of your items datasets using the keyword `scaling_factor`. \n",
    "\n",
    "The input is a list of dictionaries where the format of each dictionary is as follows: {\"column\": \"col0\", \"values\": [\"value0\", \"value1\"], \"factor\": 1.1}. \n",
    "\n",
    "The command below is using scaling factors based on the column \"Genres\" to add positive bias to the comedies with a scaling factor of 3, and a negative bias to the dramas with a scaling factor of 0.25.\n",
    "\n",
    "We now have a Comedy in the second recommendation for user ID 10 (while in the unscaled run, there was no Comedy in the first 50 recommendations). Similarly there is no more Drama|Romance in her first 10 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 96258,
     "status": "aborted",
     "timestamp": 1609881728417,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "xGzQ-4M8dTEM"
   },
   "outputs": [],
   "source": [
    "recommendations_scaling = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    num_items=10,\n",
    "    score_field = \"score\",\n",
    "    scaling_factors=[\n",
    "        {\"column\": \"genres\", \"values\": [\"Comedy\"], \"factor\": 3},\n",
    "        {\"column\": \"genres\", \"values\": [\"Drama\"], \"factor\": 0.25},\n",
    "    ],\n",
    ")\n",
    "recommendations_scaling_df = pd.DataFrame(recommendations_scaling).merge(movies, on=\"movie_id\")\n",
    "recommendations_scaling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jX9h_4weRPX"
   },
   "source": [
    "### Item exclusion\n",
    "\n",
    "You can also exclude certain items from the list of recommendations using the keyword `exclude_items`. The command below is removing with genres Comedy|Romance and Drama|Romance from the recommendations list for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 92759,
     "status": "aborted",
     "timestamp": 1609881728418,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "pmQsHG-eeR4l"
   },
   "outputs": [],
   "source": [
    "recommendations_excluded = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    score_field = \"score\",\n",
    "    exclude_items=[{\"column\": \"genres\", \"values\": [\"Comedy|Romance\", \"Drama|Romance\"]}],\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_excluded_df = pd.DataFrame(recommendations_excluded).merge(movies, on=\"movie_id\")\n",
    "recommendations_excluded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IoBA6nweUBq"
   },
   "source": [
    "### Item restriction\n",
    "\n",
    "You can also restrict the list of recommendations to certain items using the keyword `restrict_items`. \n",
    "\n",
    "The input is a list of dictionaries where the format of each dictionary is as follows: {\"column\": \"col0\", \"values\": [\"value0\", \"value1\", \"value3\", ...]}\n",
    "\n",
    "The command below is returning only comedies and dramas in the user recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82586,
     "status": "aborted",
     "timestamp": 1609881728419,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "x3wsjV-FeVs9"
   },
   "outputs": [],
   "source": [
    "recommendations_restricted = ApiClient().get_recommendations(\n",
    "    deployment_token=deployment_token, \n",
    "    deployment_id=recommendations_deployment.deployment_id, \n",
    "    query_data=my_query_data,\n",
    "    score_field = \"score\",\n",
    "    restrict_items=[{\"column\": \"genres\", \"values\": [\"Comedy\", \"Drama\"]}],\n",
    "    num_items=10,\n",
    ")\n",
    "recommendations_restricted_df = pd.DataFrame(recommendations_restricted).merge(movies, on=\"movie_id\")\n",
    "recommendations_restricted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyCQKAfDU3SV"
   },
   "source": [
    "### Compare the different user recommendations\n",
    "\n",
    "We can compare the recommendation results with pandas commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 74143,
     "status": "aborted",
     "timestamp": 1609881728421,
     "user": {
      "displayName": "miguel gillot",
      "photoUrl": "",
      "userId": "06247190833821281539"
     },
     "user_tz": -60
    },
    "id": "Ojwe-7JrU-OI"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.concat(\n",
    "    [\n",
    "        recommendations_base_df[\"movie\"],\n",
    "        recommendations_scaling_df[\"movie\"],\n",
    "        recommendations_excluded_df[\"movie\"],\n",
    "        recommendations_restricted_df[\"movie\"],\n",
    "    ],\n",
    "    axis=1,\n",
    "    ignore_index=True\n",
    ")\n",
    "dataframe.columns = [\"Without Filter\", \"With Scaling Factor\", \"With Exclusion List\", \"With Restricted List\"]\n",
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Personalized Recommendations Notebook.ipynb",
   "provenance": [
    {
     "file_id": "1eGkb37EOSviuiOMYdc74ahPMS9eTkIIY",
     "timestamp": 1609882872216
    },
    {
     "file_id": "https://github.com/abacusai/notebooks/blob/main/Use%20Cases/Personalized%20Recommendations%20Notebook.ipynb",
     "timestamp": 1607911901788
    }
   ],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
