{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C9IEcYV_iZh"
   },
   "source": [
    "## How-to guide for Real-Time Forecasting use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a real-time forecasting model using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [Household Electricity Usage Dataset](https://s3.amazonaws.com/realityengines.exampledatasets/rtforecasting/household_electricity_usage.csv), which contains data about electricity usage in a specified household."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKbimuye_5P8"
   },
   "source": [
    "1. Install the Abacus.AI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0WStChzikct"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8rrYtzx_80l"
   },
   "source": [
    "We'll also import pandas and pprint tools for neat visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5NOxjIlivMC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # A tool we'll use to download and preview CSV files\n",
    "import pprint # A tool to pretty print dictionary outputs\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-35NaOTT__Wx"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG8cUIzSix-A"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "\n",
    "api_key = ''  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3GdvcMdABM8"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg4kl96gizR6"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_q7nUwrADgC"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model possible for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the available Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mb2bdmAfi0cK"
   },
   "outputs": [],
   "source": [
    "client.list_use_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuYYFCQcAJYz"
   },
   "source": [
    "In this notebook, we're going to create a real-time forecasting model using the Household Electricity Usage dataset. The 'ENERGY' use case is best tailored for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B81MrzLLi1-9"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "\n",
    "use_case = 'ENERGY'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGm4-JnUAOhj"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stifLaX0i-kA"
   },
   "outputs": [],
   "source": [
    "for requirement in client.describe_use_case_requirements(use_case):\n",
    "  pp.pprint(requirement.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIvPIQdrAQh5"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ji7nzh7ujAIR"
   },
   "outputs": [],
   "source": [
    "real_time_project = client.create_project(name='Electricity Usage Forecasting', use_case=use_case)\n",
    "real_time_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zhnJrCG1Nfx"
   },
   "source": [
    "**Note: When feature_groups_enabled is True then the use case supports feature groups (collection of ML features). Feature groups are created at the organization level and can be tied to a project to further use it for training ML models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NeRTkfLATR5"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using one dataset for this notebook. We'll tell Abacus.AI how the dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [Household Electricity Usage Dataset](https://s3.amazonaws.com/realityengines.exampledatasets/rtforecasting/household_electricity_usage.csv) (**TIMESERIES**): \n",
    "This dataset contains information about electricity usage in specified households over a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x7RSou5Ae-1"
   },
   "source": [
    "### Add the dataset to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the file, then add it to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP9vhBMpe7Rv"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com/realityengines.exampledatasets/rtforecasting/household_electricity_usage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XA5b9pTAhIe"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-o7hNMCe718"
   },
   "outputs": [],
   "source": [
    "real_time_dataset = client.create_dataset_from_file_connector(name='Household Electricity Usage',table_name='Household_Electricity_Usage',\n",
    "                                     location='s3://realityengines.exampledatasets/rtforecasting/household_electricity_usage.csv',\n",
    "                                     refresh_schedule='0 12 * * *')\n",
    "datasets = [real_time_dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.wait_for_inspection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzmDkh-41Q-1"
   },
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV9lzX_EXu3T"
   },
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='real_time_forecasting',sql='SELECT * FROM Household_Electricity_Usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyjiXlnN1eRz"
   },
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GECYDzWFXu6p"
   },
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = real_time_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLJjEjKE1crJ"
   },
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Dbbl6qI1c1k"
   },
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = real_time_project.project_id, feature_group_type= \"TIMESERIES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EC4HMcUUzmL2"
   },
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-xA4CcqXvQN"
   },
   "outputs": [],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTh1gkvtApnD"
   },
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psFHlxSzjCGG"
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIdfg9KfYrTy"
   },
   "outputs": [],
   "source": [
    "client.set_feature_mapping(project_id = real_time_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='value',feature_mapping='TARGET')\n",
    "client.set_feature_mapping(project_id = real_time_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='time',feature_mapping='DATE')\n",
    "client.set_feature_mapping(project_id = real_time_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='id',feature_mapping='ITEM_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W22uAj4bAvW9"
   },
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKoiftY0j3TG"
   },
   "outputs": [],
   "source": [
    "real_time_project.validate(feature_group_ids=[feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLnozF7iAtnf"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbeXVyMFAy4J"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "codpuGdzj5Mp"
   },
   "outputs": [],
   "source": [
    "real_time_project.get_training_config_options(feature_group_ids=[feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGVMoOJxA1iX"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBqdxHYMj6Xg"
   },
   "outputs": [],
   "source": [
    "real_time_model = real_time_project.train_model(training_config={},feature_group_ids=[feature_group.feature_group_id])\n",
    "real_time_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRydhua9A5OT"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZLUwj3_j8AH"
   },
   "outputs": [],
   "source": [
    "real_time_model.wait_for_full_automl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS6dDGHC2Hvu"
   },
   "source": [
    "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G_IrWmbA7vZ"
   },
   "source": [
    "## **Checkpoint** [Optional]\n",
    "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeNOLyfnA877"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)\n",
    "real_time_project = next(project for project in client.list_projects() if project.name == 'Electricity Usage Forecasting')\n",
    "real_time_model = real_time_project.list_models()[-1]\n",
    "real_time_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw7POj4tBKTG"
   },
   "source": [
    "## Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ8AH0xsj9ts"
   },
   "outputs": [],
   "source": [
    "pp.pprint(real_time_model.get_metrics().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me7R75zPBMbW"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/ENERGY/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKr0VRyiBV8S"
   },
   "source": [
    "## 5. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9pQBRmPBbk1"
   },
   "source": [
    "After the model has been trained, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThqR7zVXkAa-"
   },
   "outputs": [],
   "source": [
    "deployment_token = real_time_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DascIt8KBWQW"
   },
   "source": [
    "Now we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aGgzb95j_AF"
   },
   "outputs": [],
   "source": [
    "real_time_deployment = client.create_deployment(name='Electricity Usage Deployment',description='Electricity Usage Deployment',model_id=real_time_model.model_id)\n",
    "real_time_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d7RMuJwBc5G"
   },
   "source": [
    "## 6. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FgHz2XOBdQn"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_forecast` API call below.\n",
    "\n",
    "This command will return a forecast under each percentile for the specified ITEM_ID. The forecast will be performed based on attributes specified in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6n-vz0lkB65"
   },
   "outputs": [],
   "source": [
    "ApiClient().get_forecast(deployment_token=deployment_token, \n",
    "               deployment_id=real_time_deployment.deployment_id, \n",
    "               query_data={\"id\":\"MT_001\"})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Real-time Forecasting Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a444a4e97a0365a8a152d6b3286685b7a3c540a2b13f4d560bd58f028f75a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
