{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddP4J1g68RJI"
   },
   "source": [
    "## How-to guide for Customer Churn use-case on Abacus.AI platform\n",
    "This notebook provides you with a hands on environment to build a customer churn prediction model using the Abacus.AI Python Client Library.\n",
    "\n",
    "We'll be using the [Telco Customer Churn Dataset](https://s3.amazonaws.com//realityengines.exampledatasets/customer_churn/telco.csv), which contains information about multiple users, their attributes, and whether or not they churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q07yJYbl8jRf"
   },
   "source": [
    "1. Install the Abacus.AI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Q6TANGq2ew"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvzIcK0f8k10"
   },
   "source": [
    "We'll also import pandas and pprint tools for visualization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwPpORt-q_P1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # A tool we'll use to download and preview CSV files\n",
    "import pprint # A tool to pretty print dictionary outputs\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02oc2aQx8n9v"
   },
   "source": [
    "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6dWZh0mrI1c"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI API Key\n",
    "api_key = ''  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxg00rPH8qmv"
   },
   "source": [
    "3. Import the Abacus.AI library and instantiate a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNfA4MU6rKOA"
   },
   "outputs": [],
   "source": [
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpXXFg4n8spr"
   },
   "source": [
    "## 1. Create a Project\n",
    "\n",
    "Abacus.AI projects are containers that have ML features and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model catered specifically for your data.\n",
    "\n",
    "We'll call the `list_use_cases` method to retrieve a list of the Use Cases currently available on the Abacus.AI platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1f_-ap7rMYv"
   },
   "outputs": [],
   "source": [
    "client.list_use_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jimfsdFf8t2U"
   },
   "source": [
    "In this notebook, we're going to create a customer churn prediction model using the Telco Customer Churn dataset. The 'CUSTOMER_CHURN' use case is best tailored for this situation. For the purpose of taking an example, we will be using the [Telco Customer Churn Dataset](https://s3.amazonaws.com//realityengines.exampledatasets/customer_churn/telco.csv) that has user information, attributes, and whether or not they churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8is59yg9rN2a"
   },
   "outputs": [],
   "source": [
    "#@title Abacus.AI Use Case\n",
    "use_case = 'CUSTOMER_CHURN'  #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkRaPf4t80Ww"
   },
   "source": [
    "By calling the `describe_use_case_requirements` method we can view what features are required for this use_case and what features are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsyiQeZBrQox"
   },
   "outputs": [],
   "source": [
    "for requirement in client.describe_use_case_requirements(use_case):\n",
    "  pp.pprint(requirement.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfaARhOL83Lk"
   },
   "source": [
    "Finally, let's create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bD_jOVUFrRz4"
   },
   "outputs": [],
   "source": [
    "churn_project = client.create_project(name='Customer Churn Prediction', use_case=use_case)\n",
    "churn_project.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: When feature_groups_enabled is True then the use case supports feature groups (collection of ML features). Feature groups are created at the organization level and can be tied to a project to further use it for training ML models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul4eakvYEkEJ"
   },
   "source": [
    "## 2. Add Datasets to your Project\n",
    "\n",
    "Abacus.AI can read datasets directly from `AWS S3`, `Google Cloud Storage`, and other cloud storage buckets, you can also connect your dataset connector and pull your data from them (bigquery, snowflake, etc.). Otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
    "\n",
    "We are using one dataset for this notebook. We'll tell Abacus.AI how the dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
    "- [Telco Customer Churn Dataset](https://s3.amazonaws.com//realityengines.exampledatasets/customer_churn/telco.csv) (**USER_ATTRIBUTES**): \n",
    "This dataset contains information about multiple users for a specified company, along with whether or not they churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aomom3Q19MB9"
   },
   "source": [
    "### Add the dataset to Abacus.AI\n",
    "\n",
    "First we'll use Pandas to preview the file, then add it to Abacus.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya8X1qm0rXn9"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/customer_churn/telco.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFOlKo8P9JSJ"
   },
   "source": [
    "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
    "\n",
    "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
    "\n",
    "**Note: This cron string will be evaluated in UTC time zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XOVpmKErjkE"
   },
   "outputs": [],
   "source": [
    "churn_dataset = client.create_dataset_from_file_connector(name='Telco Customer Churn',\n",
    "                                     location='s3://realityengines.exampledatasets/customer_churn/telco.csv', table_name='churn_prediction', refresh_schedule = '0 12 * * *')\n",
    "\n",
    "datasets = [churn_dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.wait_for_inspection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Feature Groups and add them to your Project\n",
    "\n",
    "Datasets are created at the organization level and can be used to create feature groups as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = client.create_feature_group(table_name='churn_pred_fg', sql='SELECT * FROM churn_prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Feature Group to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = churn_project.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the Feature Group type according to the use case requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = churn_project.project_id, feature_group_type= \"USER_ATTRIBUTES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2KHhw9D9RCE"
   },
   "source": [
    "Check current Feature Group schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00uO2jYw9Swu"
   },
   "source": [
    "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lmf335Ulr9cl"
   },
   "outputs": [],
   "source": [
    "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_mapping(project_id = churn_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='Churn',feature_mapping='CHURNED_YN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_feature_group_column_mapping(project_id = churn_project.project_id,feature_group_id= feature_group.feature_group_id, column='customerID',column_mapping='USER_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
    "\n",
    "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_project.validate(feature_group_ids= [feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-NAMlPK9aNo"
   },
   "source": [
    "## 4. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4e20jc39m6X"
   },
   "source": [
    "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om4lWyg3sbFs"
   },
   "outputs": [],
   "source": [
    "churn_project.get_training_config_options(feature_group_ids= [feature_group.feature_group_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJwXinxc9op2"
   },
   "source": [
    "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCNUnNrIsc-5"
   },
   "outputs": [],
   "source": [
    "churn_model = churn_project.train_model(training_config={},feature_group_ids= [feature_group.feature_group_id])\n",
    "churn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VAz1mew9t98"
   },
   "source": [
    "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5tAAbF7shT7"
   },
   "outputs": [],
   "source": [
    "churn_model.wait_for_full_automl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQmikFI69voK"
   },
   "source": [
    "## **Checkpoint** [Optional]\n",
    "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGZpsw679wTf"
   },
   "outputs": [],
   "source": [
    "!pip install abacusai\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "api_key = ''  #@param {type: \"string\"}\n",
    "from abacusai import ApiClient\n",
    "client = ApiClient(api_key)\n",
    "churn_project = next(project for project in client.list_projects() if project.name == 'Customer Churn Prediction')\n",
    "churn_model = churn_project.list_models()[-1]\n",
    "churn_model.wait_for_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYYlzif_96cq"
   },
   "source": [
    "## 5. Evaluate your Model Metrics\n",
    "\n",
    "After your model is done training you can inspect the model's quality by reviewing the model's metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xMbq3Gxsjot"
   },
   "outputs": [],
   "source": [
    "pp.pprint(churn_model.get_metrics().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSnO3E__981U"
   },
   "source": [
    "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/CUSTOMER_CHURN/training) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxo469uk-C-u"
   },
   "source": [
    "## 6. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPckbCKK-Ggl"
   },
   "source": [
    "After the model has been trained, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgcMV2vasmPz"
   },
   "outputs": [],
   "source": [
    "deployment_token = churn_project.create_deployment_token().deployment_token\n",
    "deployment_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXSSPA7u-DPE"
   },
   "source": [
    "Now we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQUlbDyxslCn"
   },
   "outputs": [],
   "source": [
    "churn_deployment = client.create_deployment(name='Customer Churn Deployment', description='Customer Churn Prediction Model Deployment', model_id=churn_model.model_id)\n",
    "churn_deployment.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-MxqAGG-ITD"
   },
   "source": [
    "## 7. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H92B6oiv-Jnc"
   },
   "source": [
    "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `predict_churn` API call below.\n",
    "\n",
    "This command will return the probability of a user with specified attributes churning. The prediction would be performed based on the specified dataset, which, in this case, contains information about the user, their attributes, and whether or not they churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyxbYJ03snPK"
   },
   "outputs": [],
   "source": [
    "ApiClient().predict_churn(deployment_token=deployment_token, \n",
    "               deployment_id=churn_deployment.deployment_id, \n",
    "               query_data={\"MonthlyCharges\":69.7,\"TotalCharges\":560.85,\"gender\":\"Male\",\"SeniorCitizen\":\"1\",\"Partner\":\"No\",\"Dependents\":\"No\",\"tenure\":\"8\",\"PhoneService\":\"Yes\",\"MultipleLines\":\"No\",\"InternetService\":\"Fiber optic\",\"OnlineSecurity\":\"No\",\"OnlineBackup\":\"No\",\"DeviceProtection\":\"No\",\"TechSupport\":\"No\",\"StreamingTV\":\"No\",\"StreamingMovies\":\"No\",\"Contract\":\"Month-to-month\",\"PaperlessBilling\":\"Yes\",\"PaymentMethod\":\"Electronic check\"})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Customer Churn Prediction Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a444a4e97a0365a8a152d6b3286685b7a3c540a2b13f4d560bd58f028f75a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
